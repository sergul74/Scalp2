{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 — Data Download\n",
    "Download BTC/USDT OHLCV data (15m, 1H, 4H) from Binance via CCXT.\n",
    "Caches to parquet files on Google Drive for persistence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install dependencies\n# torch, numpy, pandas are pre-installed by Colab — do NOT reinstall them.\n# Pinning versions fights Colab's environment and causes resolver conflicts.\n!pip install -q xgboost ccxt PyWavelets hmmlearn numba scikit-learn pyyaml \\\n    tensorboard tqdm pyarrow"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive and clone/pull repo\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "REPO_DIR = '/content/scalp2'\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone https://github.com/<YOUR_USERNAME>/scalp2.git {REPO_DIR}\n",
    "else:\n",
    "    !cd {REPO_DIR} && git pull\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, REPO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(name)s %(levelname)s: %(message)s')\n",
    "\n",
    "from scalp2.config import load_config\n",
    "config = load_config(f'{REPO_DIR}/config.yaml')\n",
    "\n",
    "# Colab often hits HTTP 451 on Binance USD-M endpoints.\n",
    "# Use Bybit linear perpetual by default in Colab.\n",
    "if config.data.exchange == 'binanceusdm':\n",
    "    config.data.exchange = 'bybit'\n",
    "    config.data.symbol = 'BTC/USDT:USDT'\n",
    "\n",
    "# Override cache dir to Google Drive for persistence\n",
    "config.data.cache_dir = '/content/drive/MyDrive/scalp2/data/raw'\n",
    "config.data.processed_dir = '/content/drive/MyDrive/scalp2/data/processed'\n",
    "\n",
    "os.makedirs(config.data.cache_dir, exist_ok=True)\n",
    "os.makedirs(config.data.processed_dir, exist_ok=True)\n",
    "\n",
    "print(f'Symbol: {config.data.symbol}')\n",
    "print(f'Date range: {config.data.date_range.start} to {config.data.date_range.end}')\n",
    "print(f'Timeframes: {config.data.timeframes.primary}, {config.data.timeframes.mtf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scalp2.data.downloader import OHLCVDownloader\n",
    "\n",
    "downloader = OHLCVDownloader(config.data)\n",
    "data = downloader.fetch_all(use_cache=True)\n",
    "\n",
    "for tf, df in data.items():\n",
    "    print(f'{tf}: {len(df)} bars, {df.index[0] if hasattr(df, \"index\") else df[\"timestamp\"].iloc[0]} → {df.index[-1] if hasattr(df, \"index\") else df[\"timestamp\"].iloc[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download funding rate data\n",
    "funding_df = downloader.fetch_funding_rate(use_cache=True)\n",
    "print(f'Funding rates: {len(funding_df)} records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and preprocess\n",
    "from scalp2.data.preprocessing import clean_ohlcv\n",
    "\n",
    "for tf in data:\n",
    "    data[tf] = clean_ohlcv(data[tf], tf)\n",
    "    print(f'{tf} after cleaning: {len(data[tf])} bars')\n",
    "\n",
    "# Save cleaned data\n",
    "for tf, df in data.items():\n",
    "    path = f'{config.data.processed_dir}/BTC_USDT_{tf}_clean.parquet'\n",
    "    df.to_parquet(path)\n",
    "    print(f'Saved {path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
