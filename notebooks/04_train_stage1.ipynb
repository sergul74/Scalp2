{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 â€” Stage 1 Training (TCN + GRU)\n",
    "Train the HybridEncoder using purged walk-forward CV with AMP.\n",
    "Saves model checkpoints and latent vectors per fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch xgboost ccxt PyWavelets pandas-ta hmmlearn numba scikit-learn pyyaml tensorboard tqdm pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import sys, os, json\n",
    "REPO_DIR = '/content/scalp2'\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone https://github.com/<YOUR_USERNAME>/scalp2.git {REPO_DIR}\n",
    "sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(name)s %(levelname)s: %(message)s')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from scalp2.config import load_config\n",
    "config = load_config(f'{REPO_DIR}/config.yaml')\n",
    "\n",
    "DATA_DIR = '/content/drive/MyDrive/scalp2/data/processed'\n",
    "CHECKPOINT_DIR = '/content/drive/MyDrive/scalp2/checkpoints'\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labeled dataset\n",
    "df = pd.read_parquet(f'{DATA_DIR}/BTC_USDT_labeled.parquet')\n",
    "with open(f'{DATA_DIR}/feature_columns.json', 'r') as f:\n",
    "    feature_cols = json.load(f)\n",
    "\n",
    "print(f'Dataset: {len(df)} rows, {len(feature_cols)} features')\n",
    "print(f'Labels: {df[\"tb_label_cls\"].value_counts().sort_index().to_dict()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scalp2.training.walk_forward import PurgedWalkForwardCV\n",
    "from scalp2.models.hybrid import HybridEncoder\n",
    "from scalp2.training.trainer import Stage1Trainer\n",
    "from scalp2.regime.hmm import RegimeDetector\n",
    "from scalp2.utils.serialization import save_fold_artifacts\n",
    "from scalp2.utils.memory import log_gpu_memory, estimate_batch_memory\n",
    "\n",
    "cv = PurgedWalkForwardCV(config.training.walk_forward)\n",
    "n_folds = cv.n_folds(len(df))\n",
    "print(f'Walk-forward: {n_folds} folds')\n",
    "\n",
    "# Pre-flight memory check\n",
    "n_features = len(feature_cols)\n",
    "mem_est = estimate_batch_memory(\n",
    "    config.training.batch_size, config.model.seq_len,\n",
    "    n_features, 315000, config.training.use_amp\n",
    ")\n",
    "print(f'Estimated GPU memory: {mem_est[\"total_estimated_mb\"]:.0f} MB (fits T4: {mem_est[\"fits_t4\"]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume support: check which folds are already done\n",
    "completed_folds = set()\n",
    "for p in os.listdir(CHECKPOINT_DIR) if os.path.exists(CHECKPOINT_DIR) else []:\n",
    "    if p.startswith('fold_') and os.path.isdir(os.path.join(CHECKPOINT_DIR, p)):\n",
    "        try:\n",
    "            idx = int(p.split('_')[1])\n",
    "            completed_folds.add(idx)\n",
    "        except ValueError:\n",
    "            pass\n",
    "print(f'Already completed folds: {sorted(completed_folds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "all_results = []\n",
    "features_array = df[feature_cols].values\n",
    "labels_array = df['tb_label_cls'].values\n",
    "returns_array = df['tb_return'].values\n",
    "\n",
    "for fold in cv.split(len(df)):\n",
    "    if fold.fold_idx in completed_folds:\n",
    "        print(f'Skipping fold {fold.fold_idx} (already completed)')\n",
    "        continue\n",
    "    \n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'FOLD {fold.fold_idx}/{n_folds-1}')\n",
    "    print(f'Train: [{fold.train_start}:{fold.train_end}] Val: [{fold.val_start}:{fold.val_end}] Test: [{fold.test_start}:{fold.test_end}]')\n",
    "    print(f'{\"=\"*60}')\n",
    "    \n",
    "    # Extract fold data\n",
    "    train_feat = features_array[fold.train_start:fold.train_end]\n",
    "    train_labels = labels_array[fold.train_start:fold.train_end]\n",
    "    train_returns = returns_array[fold.train_start:fold.train_end]\n",
    "    \n",
    "    val_feat = features_array[fold.val_start:fold.val_end]\n",
    "    val_labels = labels_array[fold.val_start:fold.val_end]\n",
    "    val_returns = returns_array[fold.val_start:fold.val_end]\n",
    "    \n",
    "    # Scale features (fit on train only)\n",
    "    scaler = RobustScaler()\n",
    "    train_feat_scaled = scaler.fit_transform(train_feat).astype(np.float32)\n",
    "    val_feat_scaled = scaler.transform(val_feat).astype(np.float32)\n",
    "    \n",
    "    # Fit HMM regime detector on training data\n",
    "    regime_detector = RegimeDetector(config.regime)\n",
    "    train_df_for_regime = df.iloc[fold.train_start:fold.train_end]\n",
    "    regime_detector.fit(train_df_for_regime)\n",
    "    \n",
    "    # Initialize model (fresh for each fold)\n",
    "    model = HybridEncoder(n_features, config.model)\n",
    "    print(f'Model parameters: {model.count_parameters():,}')\n",
    "    \n",
    "    # Train\n",
    "    trainer = Stage1Trainer(model, config.training, checkpoint_dir=CHECKPOINT_DIR)\n",
    "    result = trainer.train_one_fold(\n",
    "        train_feat_scaled, train_labels, train_returns,\n",
    "        val_feat_scaled, val_labels, val_returns,\n",
    "        fold_idx=fold.fold_idx,\n",
    "        seq_len=config.model.seq_len,\n",
    "    )\n",
    "    \n",
    "    # Save all artifacts\n",
    "    save_fold_artifacts(\n",
    "        CHECKPOINT_DIR, fold.fold_idx,\n",
    "        model.state_dict(), scaler,\n",
    "        np.array([]),  # top_feature_indices set in stage 2\n",
    "        feature_cols,\n",
    "        regime_detector,\n",
    "        metadata={'result': {k: v for k, v in result.items() if k != 'history'}},\n",
    "    )\n",
    "    \n",
    "    all_results.append(result)\n",
    "    log_gpu_memory(f'Fold {fold.fold_idx} done')\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    del model, trainer\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'\\nAll folds complete. Results: {len(all_results)} folds trained.')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
