{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 â€” Stage 2 Training (XGBoost Meta-Learner)\n",
    "Extract latent vectors from trained Stage-1 models, combine with\n",
    "handcrafted features and regime probabilities, train XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch xgboost ccxt PyWavelets pandas-ta hmmlearn numba scikit-learn pyyaml 'numpy>=1.26.0,<2.2.0' 'pandas==2.2.2' tqdm pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import sys, os, json\n",
    "REPO_DIR = '/content/scalp2'\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone https://github.com/<YOUR_USERNAME>/scalp2.git {REPO_DIR}\n",
    "sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(name)s %(levelname)s: %(message)s')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from scalp2.config import load_config\n",
    "config = load_config(f'{REPO_DIR}/config.yaml')\n",
    "\n",
    "DATA_DIR = '/content/drive/MyDrive/scalp2/data/processed'\n",
    "CHECKPOINT_DIR = '/content/drive/MyDrive/scalp2/checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_parquet(f'{DATA_DIR}/BTC_USDT_labeled.parquet')\n",
    "with open(f'{DATA_DIR}/feature_columns.json', 'r') as f:\n",
    "    feature_cols = json.load(f)\n",
    "\n",
    "features_array = df[feature_cols].values\n",
    "labels_array = df['tb_label_cls'].values\n",
    "returns_array = df['tb_return'].values\n",
    "print(f'Dataset: {len(df)} rows, {len(feature_cols)} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scalp2.training.walk_forward import PurgedWalkForwardCV\n",
    "from scalp2.models.hybrid import HybridEncoder\n",
    "from scalp2.training.trainer import Stage1Trainer\n",
    "from scalp2.training.stage2_trainer import Stage2Trainer\n",
    "from scalp2.regime.hmm import RegimeDetector\n",
    "from scalp2.utils.serialization import load_fold_artifacts\n",
    "from scalp2.utils.metrics import evaluate_predictions\n",
    "\n",
    "cv = PurgedWalkForwardCV(config.training.walk_forward)\n",
    "stage2 = Stage2Trainer(config, checkpoint_dir=CHECKPOINT_DIR)\n",
    "n_features = len(feature_cols)\n",
    "\n",
    "all_test_results = []\n",
    "\n",
    "for fold in cv.split(len(df)):\n",
    "    print(f'\\n--- Fold {fold.fold_idx} ---')\n",
    "    \n",
    "    # Load Stage-1 artifacts\n",
    "    artifacts = load_fold_artifacts(CHECKPOINT_DIR, fold.fold_idx)\n",
    "    \n",
    "    # Reconstruct model and load weights\n",
    "    model = HybridEncoder(n_features, config.model)\n",
    "    model.load_state_dict(artifacts['model_state'])\n",
    "    \n",
    "    trainer = Stage1Trainer(model, config.training, checkpoint_dir=CHECKPOINT_DIR)\n",
    "    regime_detector = artifacts.get('regime_detector')\n",
    "    \n",
    "    if regime_detector is None:\n",
    "        regime_detector = RegimeDetector(config.regime)\n",
    "        regime_detector.fit(df.iloc[fold.train_start:fold.train_end])\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = artifacts['scaler']\n",
    "    train_scaled = scaler.transform(features_array[fold.train_start:fold.train_end]).astype(np.float32)\n",
    "    val_scaled = scaler.transform(features_array[fold.val_start:fold.val_end]).astype(np.float32)\n",
    "    test_scaled = scaler.transform(features_array[fold.test_start:fold.test_end]).astype(np.float32)\n",
    "    \n",
    "    # Run Stage 2\n",
    "    result = stage2.train_one_fold(\n",
    "        trainer, regime_detector,\n",
    "        train_scaled, labels_array[fold.train_start:fold.train_end],\n",
    "        val_scaled, labels_array[fold.val_start:fold.val_end],\n",
    "        test_scaled, labels_array[fold.test_start:fold.test_end],\n",
    "        df.iloc[fold.train_start:fold.train_end],\n",
    "        df.iloc[fold.val_start:fold.val_end],\n",
    "        df.iloc[fold.test_start:fold.test_end],\n",
    "        feature_cols, fold.fold_idx,\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    metrics = evaluate_predictions(\n",
    "        result['test_probabilities'], result['test_labels'],\n",
    "        returns_array[fold.test_start + config.model.seq_len:fold.test_end][:len(result['test_labels'])],\n",
    "        config.execution.confidence_threshold,\n",
    "    )\n",
    "    print(f'Fold {fold.fold_idx} metrics: {metrics}')\n",
    "    \n",
    "    result['metrics'] = metrics\n",
    "    all_test_results.append(result)\n",
    "    \n",
    "    # Clean up\n",
    "    del model, trainer\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate results\n",
    "metrics_df = pd.DataFrame([r['metrics'] for r in all_test_results if 'n_trades' in r['metrics'] and r['metrics']['n_trades'] > 0])\n",
    "print('\\n=== Aggregate Walk-Forward Results ===')\n",
    "print(metrics_df.describe().round(4))\n",
    "print(f'\\nMean Sharpe: {metrics_df[\"sharpe\"].mean():.4f}')\n",
    "print(f'Mean Win Rate: {metrics_df[\"win_rate\"].mean():.4f}')\n",
    "print(f'Mean Trades/Day: {metrics_df[\"trades_per_day\"].mean():.2f}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
